{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae50b27-7728-4873-8528-50b9aba36410",
   "metadata": {},
   "source": [
    "# N-Grams \n",
    "\n",
    "**N-Grams** are **contiguous sequences of `n` items (usually words or characters)** from a given text.\n",
    "\n",
    "- `n = 1` â†’ **Unigram**\n",
    "- `n = 2` â†’ **Bigram**\n",
    "- `n = 3` â†’ **Trigram**\n",
    "- `n > 3` â†’ **Higher-order n-grams**\n",
    "\n",
    "ðŸ“Œ N-grams capture **local context** in text.\n",
    "\n",
    "\n",
    "### Types of N-Grams\n",
    "\n",
    "#### ðŸ”¹ Word N-Grams\n",
    "Based on words.\n",
    "\n",
    "Example sentence:\n",
    "\"I love natural language processing\"\n",
    "\n",
    "\n",
    "| Type | Output |\n",
    "|----|----|\n",
    "| Unigram | I, love, natural, language, processing |\n",
    "| Bigram | I love, love natural, natural language, language processing |\n",
    "| Trigram | I love natural, love natural language, natural language processing |\n",
    "\n",
    "\n",
    "#### ðŸ”¹ Character N-Grams\n",
    "Based on characters.\n",
    "\n",
    "Example word:\n",
    "\"NLP\"\n",
    "\n",
    "\n",
    "- Character bigrams â†’ `NL`, `LP`\n",
    "- Character trigrams â†’ `NLP`\n",
    "\n",
    "\n",
    "### Why N-Grams are Used\n",
    "\n",
    "- Capture **word order**\n",
    "- Improve **context understanding**\n",
    "- Useful in **language modeling**\n",
    "- Improve accuracy over Bag of Words\n",
    "\n",
    "\n",
    "### Key Points\n",
    "\n",
    "âœ” Captures local context  âœ” Simple to implement  âœ” Improves prediction accuracy  \n",
    "\n",
    "âŒ High dimensionality  âŒ Sparse vectors  âŒ Cannot capture long-range context  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c51418-0636-4118-b23a-94471f542c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7531c5f0-8e87-46dc-815f-baabda9c4d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Purvi\n",
      "[nltk_data]     jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Purvi\n",
      "[nltk_data]     jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77381a3d-525d-46e3-9c69-0fee7a32b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''\n",
    "    I love Machine Learning, Machine Learning is powerful, I love Python and Machine Learning\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4907a4e-6ec0-4a57-a835-c9506e6ce5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n    I love Machine Learning, Machine Learning is powerful, I love Python and Machine Learning']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "054ca4f3-83f0-42f5-ba7e-ecf3a6f57ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for sentence in sentences:\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentence)  #âš  Regex [a-zA-Z] removes Unicode characters -> Use \\w and \\s for real-world NLP text\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [\n",
    "        word for word in review \n",
    "        if word not in stopwords.words('english')\n",
    "    ]\n",
    "    \n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686bbeae-0f04-4177-815c-247cdc3e1262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love machine learning machine learning powerful love python machine learning']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd4a576-c090-40bb-8aa8-6efb33d7cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(binary=True,ngram_range=(3,3)) # trigram\n",
    "cv = CountVectorizer(binary=True,ngram_range=(2,2)) # bigram\n",
    "x = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad8e6f3c-acbb-4856-a66e-65e661e01557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love machine': 2,\n",
       " 'machine learning': 4,\n",
       " 'learning machine': 0,\n",
       " 'learning powerful': 1,\n",
       " 'powerful love': 5,\n",
       " 'love python': 3,\n",
       " 'python machine': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de3a95b-4a3a-42b6-ac05-68b8db826355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b521b1-2704-4a96-b7b7-b9a7ae79c2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['learning machine', 'learning powerful', 'love machine',\n",
       "       'love python', 'machine learning', 'powerful love',\n",
       "       'python machine'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98cb716e-23f0-421f-b63c-237018c3d54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(len(cv.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec69abe-b453-44c6-9785-6a8abf0af3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning machine</th>\n",
       "      <th>learning powerful</th>\n",
       "      <th>love machine</th>\n",
       "      <th>love python</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>powerful love</th>\n",
       "      <th>python machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning machine  learning powerful  love machine  love python  \\\n",
       "0                 1                  1             1            1   \n",
       "\n",
       "   machine learning  powerful love  python machine  \n",
       "0                 1              1               1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bow_df = pd.DataFrame(\n",
    "    x.toarray(),\n",
    "    columns=cv.get_feature_names_out()\n",
    ")\n",
    "\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b9357-c27f-48e9-acaf-f8d8d0ec4362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
